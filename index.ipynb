{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "veterinary-deficit",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rural-mirror",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import output_notebook\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpine-missile",
   "metadata": {},
   "source": [
    "# Choosing some Static Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minus-prompt",
   "metadata": {},
   "source": [
    "First we need:\n",
    "    \n",
    "    * a set of documents of search over (i.e. our corpus)\n",
    "    * a set of word embeddings to employ for these searches\n",
    "    \n",
    "For the latter, we turn to Vectorian's embedding zoo, which offers a number of pretrained word embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sapphire-pressure",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vectorian.embeddings import Zoo\n",
    "\n",
    "Zoo.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "previous-twenty",
   "metadata": {},
   "source": [
    "Let's load three embeddings. To make this work in environments with little RAM we focus on low-dimension embeddings. We choose the 50-dimensions 6B glove embedding (https://nlp.stanford.edu/projects/glove/), a 50-dimension version of the English Numberbatch embedding (https://github.com/commonsense/conceptnet-numberbatch) and a compressed version of the English fastText embeddings (https://fasttext.cc/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-union",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = Zoo.load('glove-6B-50')\n",
    "numberbatch = Zoo.load('numberbatch-19.08-en-50')\n",
    "fasttext = Zoo.load('fasttext-en-mini')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accredited-contract",
   "metadata": {},
   "source": [
    "# Loading Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threaded-insertion",
   "metadata": {},
   "source": [
    "First load our gold standard that contains our queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "vietnamese-governor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"gold.json\", \"r\") as f:\n",
    "    queries = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absent-cattle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "#nlp = spacy.load(\"en_core_web_trf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rotary-shirt",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vectorian.importers import StringImporter\n",
    "from vectorian.embeddings import SpacyTransformerEmbedding\n",
    "from tqdm import tqdm\n",
    "\n",
    "#tfm_embedding = SpacyTransformerEmbedding(nlp).compressed(10)\n",
    "tfm_embedding = None\n",
    "\n",
    "def import_docs():\n",
    "    if tfm_embedding:\n",
    "        im = StringImporter(nlp, embeddings=[tfm_embedding])\n",
    "    else:\n",
    "        im = StringImporter(nlp)    \n",
    "\n",
    "    docs = []\n",
    "\n",
    "    for query in tqdm(queries, desc=\"Importing\"):\n",
    "        for m in query[\"matches\"]:\n",
    "            docs.append(im(\n",
    "                m[\"context\"],\n",
    "                title=m[\"work\"],\n",
    "                author=m[\"author\"],\n",
    "                unique_id=m[\"id\"]))\n",
    "            \n",
    "    return docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secondary-advance",
   "metadata": {},
   "source": [
    "Finally, we want to keep some additional info about the docs (inside `doc_details` and keyed by the doc's unique id). This helps us with adding nicer visuals and extended info to some of the content further down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "physical-variety",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_doc_details():\n",
    "    doc_details = {}\n",
    "\n",
    "    for query in queries:\n",
    "        for m in query[\"matches\"]:\n",
    "            doc_details[m[\"id\"]] = {\n",
    "                'query': query,\n",
    "                'match': m\n",
    "            }\n",
    "        \n",
    "    return doc_details\n",
    "                                  \n",
    "doc_details = mk_doc_details()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heavy-colleague",
   "metadata": {},
   "source": [
    "We are now ready to build a Vectorian session that contains our documents and embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capital-jewelry",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vectorian.session import LabSession\n",
    "\n",
    "session = LabSession(\n",
    "    import_docs(),\n",
    "    embeddings=[glove, numberbatch, fasttext],\n",
    "    normalizers=\"default\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proper-natural",
   "metadata": {},
   "source": [
    "Let's take a look at the documents we imported and that now live inside `session`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-austria",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "import string\n",
    "\n",
    "class DocFormatter:\n",
    "    def __init__(self):\n",
    "        self._template = string.Template(\"\"\"\n",
    "            <div style=\"margin-left:2em\">\n",
    "                <span style=\"font-variant:small-caps; font-size: 14pt;\">${title}</style>\n",
    "                <span style=\"float:right; font-size: 10pt;\">query: ${phrase}</span>\n",
    "                <hr>\n",
    "                <div style=\"font-variant:normal; font-size: 10pt;\">${text}</div>\n",
    "            </div>\n",
    "            \"\"\")\n",
    "    \n",
    "    def enhanced_doc_text(self, doc):\n",
    "        with doc.text() as text_ref:\n",
    "            text = text_ref.get()\n",
    "        quote = doc_details[doc.unique_id][\"match\"][\"quote\"]\n",
    "        try:\n",
    "            i = text.index(quote)\n",
    "            return ''.join([\n",
    "                text[:i],\n",
    "                '<span style=\"font-weight:bold;\">',\n",
    "                text[i:i + len(quote)],\n",
    "                '</span>',\n",
    "                text[i + len(quote):]\n",
    "            ])\n",
    "        except:\n",
    "            return text\n",
    "        \n",
    "    def __call__(self, doc):\n",
    "        return self._template.substitute(\n",
    "            phrase=doc_details[doc.unique_id][\"query\"][\"phrase\"],\n",
    "            title=doc.metadata[\"title\"],\n",
    "            text=self.enhanced_doc_text(doc))\n",
    "\n",
    "@interact(\n",
    "    doc_index=widgets.IntSlider(min=1, max=len(session.documents)))\n",
    "def browse_docs(doc_index):\n",
    "    doc = session.documents[doc_index - 1]\n",
    "    doc_formatter = DocFormatter()\n",
    "    display(widgets.HTML(doc_formatter(doc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loose-residence",
   "metadata": {},
   "source": [
    "# Comparing Sentence Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "musical-hampshire",
   "metadata": {},
   "source": [
    "In a first step, let's look at representing each document with one embedding in order to gather an understanding how different embedding strategies relate to the nearness of documents. We will later turn to individual token embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fiscal-interim",
   "metadata": {},
   "source": [
    "We first prepare additional sentence embeddings using SBERT that we will show in our first big visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sonic-consistency",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vectorian.embeddings import SentenceBERTEncoder\n",
    "sbert = SentenceBERTEncoder(nlp, \"paraphrase-distilroberta-base-v1\")\n",
    "\n",
    "# precompute SBERT sentence embeddings. takes a moment.\n",
    "sbert.prepare(session.partition(\"document\"), session.documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agricultural-bonus",
   "metadata": {},
   "source": [
    "In the TSNE visualization below, dots are documents and the colors are the query that yields that document in our gold standard. By hovering over dots with the mouse you get details on the document and query the dot represents. Nearby dots of the same color indicate that the embedding tends to cluster documents similar to our gold standard.\n",
    "\n",
    "You can also add an intruder text by entering a text into the text field and pressing RETURN (to refresh the plot). This will move the larger crossed circle to where the currently selected embeddings thinks that the given text should be positioned in terms of the other documents.\n",
    "\n",
    "In some cases, we can clearly make out clusters visually. For example, in the fastText embedding the blue \"to be or not be\" documents are clustered nicely. SBERT shows a green cluster of \"an old man is twice a child\". numberbatch reveals a brown cluster of \"llo, ho, ho, my lord\".\n",
    "\n",
    "Finally you can switch between different embeddings using the radio buttons. You can also enable \"free_text\" and enter custom queries that are not in our gold corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "victorian-romantic",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "from openTSNE import TSNE\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "\n",
    "import bokeh.plotting\n",
    "import bokeh.models\n",
    "import bokeh.transform\n",
    "import bokeh.palettes\n",
    "import bokeh.layouts\n",
    "\n",
    "from vectorian.embeddings import TokenAveragingEncoder\n",
    "from vectorian.index import DummyIndex\n",
    "\n",
    "\n",
    "class EmbeddingPlotter:\n",
    "    def __init__(self):\n",
    "        self.partition = session.partition(\"document\")\n",
    "\n",
    "        self.encoders = dict()\n",
    "        for embedding in session.embeddings.keys():\n",
    "            self.encoders[embedding] = TokenAveragingEncoder(\n",
    "                nlp, session.embeddings[embedding].factory)\n",
    "            \n",
    "        self._doc_formatter = DocFormatter()\n",
    "\n",
    "        self._tooltips = \"\"\"\n",
    "            <span style=\"font-variant:small-caps\">@work</span>\n",
    "            <span style=\"float:right;\">\"@query\" (@similarity%)</span>\n",
    "            <br>\n",
    "            <hr>\n",
    "            @context\n",
    "            \"\"\"\n",
    "        \n",
    "    def plot(self, embedding, intruder, show_legend=False):\n",
    "        encoder = self.encoders[embedding]\n",
    "        intruder_doc = DummyIndex(self.partition).make_query(intruder)\n",
    "        \n",
    "        id_to_doc = dict((doc.unique_id, doc) for doc in session.documents)\n",
    "        query_docs = []\n",
    "        \n",
    "        works = []\n",
    "        phrases = []\n",
    "        contexts = []\n",
    "\n",
    "        query_docs.append(intruder_doc)\n",
    "        works.append(\"\")\n",
    "        phrases.append(intruder)\n",
    "        contexts.append(\"\")\n",
    "\n",
    "        for q in queries:\n",
    "            for m in q[\"matches\"]:\n",
    "                doc = id_to_doc[m[\"id\"]]\n",
    "                query_docs.append(doc)\n",
    "                works.append(m[\"work\"])\n",
    "                phrases.append(q['phrase'])\n",
    "                contexts.append(self._doc_formatter.enhanced_doc_text(doc))\n",
    "\n",
    "        data = {\n",
    "            'work': works,\n",
    "            'query': phrases,\n",
    "            'context': contexts,\n",
    "            'vector': encoder.encode(self.partition, query_docs).unmodified\n",
    "        }\n",
    "        np.nan_to_num(data['vector'], 0)\n",
    "\n",
    "        tsne = TSNE(\n",
    "            perplexity=30,\n",
    "            metric=\"cosine\",\n",
    "            n_jobs=2,\n",
    "            random_state=42)\n",
    "\n",
    "        v = np.array(data['vector'])\n",
    "        v /= np.linalg.norm(v, axis=1)[:, np.newaxis]\n",
    "\n",
    "        similarity = [1]\n",
    "        for x in v[1:]:\n",
    "            similarity.append(np.dot(v[0], x))\n",
    "        similarity = np.array(similarity) * 100\n",
    "        \n",
    "        X = tsne.fit(v)\n",
    "\n",
    "        p = bokeh.plotting.figure(\n",
    "            plot_width=900, plot_height=len(queries) * 30,\n",
    "            title=f\"Sentence Embeddings\",\n",
    "            toolbar_location=\"below\", tools=\"pan\", tooltips=self._tooltips)\n",
    "\n",
    "        source = bokeh.models.ColumnDataSource({\n",
    "            'x': X[1:, 0],\n",
    "            'y': X[1:, 1],\n",
    "            'work': data[\"work\"][1:],\n",
    "            'query': data[\"query\"][1:],\n",
    "            'context': data[\"context\"][1:],\n",
    "            'similarity': similarity[1:]\n",
    "        })\n",
    "\n",
    "        p.circle(\n",
    "            source=source, size=10, legend_field='query',\n",
    "            color=bokeh.transform.factor_cmap(\n",
    "                'query',\n",
    "                palette=bokeh.palettes.Category20[len(queries)],\n",
    "                factors=[q['phrase'] for q in queries]),\n",
    "            alpha=0.8)\n",
    "        \n",
    "        p.circle_cross(\n",
    "            source=bokeh.models.ColumnDataSource({\n",
    "                'x': X[:1, 0],\n",
    "                'y': X[:1, 1],\n",
    "                'work': data[\"work\"][:1],\n",
    "                'query': data[\"query\"][:1],\n",
    "                'context': data[\"context\"][:1],\n",
    "                'similarity': similarity[:1]\n",
    "            }),\n",
    "            size=20,\n",
    "            color=\"blue\",\n",
    "            line_color=\"darkblue\",\n",
    "            fill_alpha=0.25)\n",
    "\n",
    "        if show_legend:\n",
    "            p.legend.orientation = \"vertical\"\n",
    "            p.legend.location = \"right\"\n",
    "            p.legend.visible = show_legend\n",
    "        else:\n",
    "            p.legend.items = []\n",
    "\n",
    "        bokeh.io.show(p)\n",
    "\n",
    "\n",
    "plotter = EmbeddingPlotter()\n",
    "plotter.encoders[\"SBERT\"] = sbert  # add the SBERT embedding\n",
    "  \n",
    "def mk_text_widget(free):\n",
    "    if not free:\n",
    "        return widgets.Dropdown(options=[q[\"phrase\"] for q in queries])\n",
    "    else:\n",
    "        return widgets.Text(\"horse\", continuous_update=False)\n",
    "    \n",
    "@interact(free_text=widgets.Checkbox())\n",
    "def plot_docs(free_text):\n",
    "    @interact(\n",
    "        query=mk_text_widget(free_text),\n",
    "        embedding=widgets.RadioButtons(options=sorted(plotter.encoders.keys())),\n",
    "        show_legend=widgets.Checkbox())\n",
    "    def inner(query, embedding, show_legend):\n",
    "        plotter.plot(embedding, query, show_legend)\n",
    "    return inner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invisible-scotland",
   "metadata": {},
   "source": [
    "Now let's run an actual search using Vectorian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fourth-engineer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vectorian.metrics import PartitionEmbeddingSimilarity, CosineSimilarity\n",
    "\n",
    "@interact(free_text=widgets.Checkbox())\n",
    "def plot_docs(free_text):\n",
    "    @interact(\n",
    "        query=mk_text_widget(free_text),\n",
    "        embedding=widgets.RadioButtons(options=sorted(plotter.encoders.keys())))\n",
    "    def inner(query, embedding):\n",
    "        sent_sim = PartitionEmbeddingSimilarity(\n",
    "            plotter.encoders[embedding],\n",
    "            CosineSimilarity())\n",
    "        index = session.partition(\"document\").index(sent_sim)\n",
    "        return index.find(query, n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forbidden-geography",
   "metadata": {},
   "source": [
    "# Exploring Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historical-jenny",
   "metadata": {},
   "source": [
    "We now turn to single word embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greatest-poland",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.word_vec(glove, \"hot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forward-booth",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vectorian.metrics import TokenSimilarity, CosineSimilarity\n",
    "\n",
    "token_sim = TokenSimilarity(\n",
    "    numberbatch,\n",
    "    CosineSimilarity()\n",
    ")\n",
    "\n",
    "session.similarity(token_sim, \"hot\", \"cold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subsequent-fishing",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_sim = TokenSimilarity(\n",
    "    glove,\n",
    "    CosineSimilarity())\n",
    "\n",
    "session.similarity(token_sim, \"hot\", \"cold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "derived-terrace",
   "metadata": {},
   "source": [
    "The following interactive board allows you to search for a custom token inside a document. You can choose different documents by changing `doc_index`. The plot gives you the similarity of the entered token with the tokens in the chosen document under the selected embedding.\n",
    "\n",
    "Note that out-of-vocabulary words like \"fasterer\" will produce zero similarities under standard key-value embeddings, whereas fastText is still able to produce a vector thanks to subword information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "together-gothic",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vectorian.metrics import TokenSimilarity, CosineSimilarity\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import bokeh.plotting\n",
    "import bokeh.models\n",
    "import bokeh.transform\n",
    "import bokeh.palettes\n",
    "\n",
    "import collections\n",
    "\n",
    "def plot_token_similarity(session, doc, token_sim, ref_token):\n",
    "    partition = session.partition(\"document\")\n",
    "    \n",
    "    color_mapper = bokeh.models.LinearColorMapper(\n",
    "        palette=\"Cividis256\", low=0, high=1)\n",
    "    \n",
    "    sim = partial(session.similarity, token_sim)\n",
    "\n",
    "    data = collections.defaultdict(list)\n",
    "    seen = set()\n",
    "    \n",
    "    for span in doc.spans(partition):\n",
    "        for k, token in enumerate(span):\n",
    "            if token.text not in seen:\n",
    "                s = max(0, sim(token.text, ref_token))\n",
    "                data['token'].append(token.text)\n",
    "                data['sim'].append(s)\n",
    "                seen.add(token.text)\n",
    "                    \n",
    "    data['sim'] = np.array(data['sim'])\n",
    "    order = np.argsort(data['sim'])[::-1]\n",
    "    data['token'] = [data['token'][i] for i in order]\n",
    "    data['sim'] = data['sim'][order]\n",
    " \n",
    "    p = bokeh.plotting.figure(\n",
    "        y_range=list(reversed(data[\"token\"])), plot_height=len(data['token']) * 20,\n",
    "        title=f\"Token Similarity for {doc.metadata['title']}\",\n",
    "        toolbar_location=None, tools=\"\")\n",
    "\n",
    "    p.hbar(\n",
    "        \"token\", right=\"sim\",\n",
    "        source=bokeh.models.ColumnDataSource(data), height=0.5,\n",
    "        color={'field': 'sim', 'transform': color_mapper})\n",
    "    \n",
    "    p.x_range = bokeh.models.Range1d(0, 1)\n",
    "    p.ygrid.grid_line_color = None\n",
    "\n",
    "    bokeh.io.show(p)\n",
    "    \n",
    "\n",
    "from ipywidgets import interact\n",
    "import ipywidgets as widgets\n",
    "\n",
    "@interact(\n",
    "    token=widgets.Text(value='high'),\n",
    "    doc_index=widgets.IntSlider(min=1, max=len(session.documents)),\n",
    "    embedding=widgets.RadioButtons(options=sorted(session.embeddings.keys())))\n",
    "def show_tokens(token, doc_index, embedding):\n",
    "    token_sim = TokenSimilarity(\n",
    "        session.embeddings[embedding].factory,\n",
    "        CosineSimilarity())\n",
    "\n",
    "    plot_token_similarity(session, session.documents[doc_index - 1], token_sim, token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulated-anderson",
   "metadata": {},
   "source": [
    "# A Search Query using Alignment over Similar Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sound-objective",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vectorian.metrics import TokenSimilarity, CosineSimilarity\n",
    "from vectorian.metrics import AlignmentSimilarity\n",
    "from vectorian.alignment import WatermanSmithBeyer, ExponentialGapCost\n",
    "\n",
    "token_sim = TokenSimilarity(\n",
    "    glove,  # the GloVe embedding we loaded earlier\n",
    "    CosineSimilarity()  # a standard cosine similarity\n",
    ")\n",
    "\n",
    "sent_sim = AlignmentSimilarity(\n",
    "    token_sim=token_sim,\n",
    "    alignment=WatermanSmithBeyer(gap=ExponentialGapCost(5), zero=0.25))\n",
    "\n",
    "index = session.partition(\"document\").index(sent_sim, nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brazilian-stewart",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries[0][\"phrase\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insured-cylinder",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.find(queries[0][\"phrase\"], n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "african-picking",
   "metadata": {},
   "source": [
    "# Plotting the NDCG over the Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriental-giving",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "import itertools\n",
    "\n",
    "import bokeh.plotting\n",
    "import bokeh.models\n",
    "import bokeh.transform\n",
    "import bokeh.palettes\n",
    "\n",
    "match_label = dict((x, i) for i, (q, x) in enumerate(\n",
    "    itertools.chain(*[[(q, m[\"id\"]) for m in q[\"matches\"]] for q in queries])))\n",
    "\n",
    "def measure_ndcg(index, query, k=10):\n",
    "    y_true = np.zeros((1, len(session.documents)), dtype=np.float32)\n",
    "    y_score = np.zeros((1, len(session.documents)), dtype=np.float32)\n",
    "\n",
    "    for m in query[\"matches\"]:\n",
    "        y_true[0, match_label[m[\"id\"]]] = 1\n",
    "    \n",
    "    for m in index.find(query[\"phrase\"], n=k).matches:\n",
    "        y_score[0, match_label[m.doc.unique_id]] = 1\n",
    "    \n",
    "    return sklearn.metrics.ndcg_score(y_true, y_score, k=k)\n",
    "\n",
    "\n",
    "def plot_ndcg(index):\n",
    "    data = {\n",
    "        'phrase': [],\n",
    "        'ndcg': []\n",
    "    }\n",
    "    for q in queries:\n",
    "        data['phrase'].append(q[\"phrase\"])\n",
    "        data['ndcg'].append(measure_ndcg(index, q))\n",
    "\n",
    "    p = bokeh.plotting.figure(\n",
    "        y_range=data['phrase'], plot_height=20 * len(queries),\n",
    "        title=\"NDCG\",\n",
    "        toolbar_location=None, tools=\"\")\n",
    "\n",
    "    source = bokeh.models.ColumnDataSource(data)\n",
    "    \n",
    "    ax = p.hbar(\n",
    "        \"phrase\", right=\"ndcg\",\n",
    "        source=source, height=0.5)\n",
    "    print(source.data)\n",
    "    \n",
    "    p.x_range = bokeh.models.Range1d(0, 1)\n",
    "\n",
    "    bokeh.io.show(p)\n",
    "    \n",
    "    \n",
    "class NDCGPlotter:\n",
    "    def _compute_ndcg(self, index):\n",
    "        return [measure_ndcg(index, q) for q in self._queries]\n",
    "    \n",
    "    def __init__(self, queries, index):\n",
    "        self._queries = queries\n",
    "        phrase = [q[\"phrase\"] for q in self._queries]\n",
    "\n",
    "        p = bokeh.plotting.figure(\n",
    "            y_range=phrase, plot_height=20 * len(self._queries),\n",
    "            title=\"NDCG\",\n",
    "            toolbar_location=None, tools=\"\")\n",
    "\n",
    "        self._source = bokeh.models.ColumnDataSource({\n",
    "            'phrase': phrase,\n",
    "            'ndcg': self._compute_ndcg(index)\n",
    "        })\n",
    "        \n",
    "        self._hbar = p.hbar(\n",
    "            \"phrase\", right=\"ndcg\",\n",
    "            source=self._source, height=0.5)\n",
    "        \n",
    "        p.x_range = bokeh.models.Range1d(0, 1)\n",
    "\n",
    "        self._bokeh_handle = bokeh.io.show(p, notebook_handle=True)\n",
    "        self._p = p\n",
    "        \n",
    "    def update(self, index):\n",
    "        self._source.data['ndcg'] = self._compute_ndcg(index)\n",
    "        bokeh.io.push_notebook(handle=self._bokeh_handle)\n",
    "    \n",
    "\n",
    "NDCGPlotter(queries, index);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "written-questionnaire",
   "metadata": {},
   "source": [
    "# Exploring WSB Parameters 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attended-andorra",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "import ipywidgets as widgets\n",
    "\n",
    "def illustrate_wsb_parameters():\n",
    "    gap_cutoff = widgets.FloatSlider(min=1, max=10, step=1, description=\"gap cutoff\")\n",
    "    zero = widgets.FloatSlider(min=0, max=1, step=0.25, description=\"zero\")\n",
    "    \n",
    "    def create_index():    \n",
    "        sent_sim = AlignmentSimilarity(\n",
    "            token_sim=token_sim,\n",
    "            alignment=WatermanSmithBeyer(gap=ExponentialGapCost(gap_cutoff.value), zero=zero.value))\n",
    "\n",
    "        return session.partition(\"document\").index(sent_sim, nlp)\n",
    "    \n",
    "    display(widgets.VBox([gap_cutoff, zero]))\n",
    "    plotter = NDCGPlotter(queries, create_index())\n",
    "    \n",
    "    def on_value_change(change):        \n",
    "        plotter.update(create_index())\n",
    "        \n",
    "    gap_cutoff.observe(on_value_change, names='value')\n",
    "    zero.observe(on_value_change, names='value')\n",
    "    \n",
    "illustrate_wsb_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loose-enough",
   "metadata": {},
   "source": [
    "# Exploring WSB Parameters 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wanted-characterization",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "import ipywidgets as widgets\n",
    "from vectorian.metrics import PNormDistance, ModifiedMetric, RadialBasis, Power\n",
    "\n",
    "def illustrate_metric_parameters():\n",
    "    p = widgets.FloatSlider(min=0.5, max=3, step=0.1, value=2, description=\"p\")\n",
    "    gamma = widgets.FloatSlider(min=0, max=3, step=0.1, value=1, description=\"gamma\")\n",
    "    alpha= widgets.FloatSlider(min=0.5, max=2, step=0.1, value=1, description=\"alpha\")\n",
    "    \n",
    "    def create_index():\n",
    "        token_sim = TokenSimilarity(\n",
    "            glove,\n",
    "            ModifiedMetric(\n",
    "                PNormDistance(p.value),\n",
    "                RadialBasis(gamma.value),\n",
    "                Power(alpha.value)))\n",
    "\n",
    "        sent_sim = AlignmentSimilarity(\n",
    "            token_sim=token_sim,\n",
    "            alignment=WatermanSmithBeyer(gap=ExponentialGapCost(5), zero=0.25))\n",
    "\n",
    "        return session.partition(\"document\").index(sent_sim, nlp)\n",
    "    \n",
    "    display(widgets.VBox([p, gamma, alpha]))\n",
    "    plotter = NDCGPlotter(queries, create_index())\n",
    "    \n",
    "    def on_value_change(change):        \n",
    "        plotter.update(create_index())\n",
    "        \n",
    "    p.observe(on_value_change, names='value')\n",
    "    gamma.observe(on_value_change, names='value')\n",
    "    alpha.observe(on_value_change, names='value')\n",
    "\n",
    "illustrate_metric_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hourly-framing",
   "metadata": {},
   "source": [
    "# Focussing in on one Query: Understanding Score and Intrusive Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infrared-union",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "import ipywidgets as widgets\n",
    "\n",
    "\n",
    "def illustrate_idea3(query_index):\n",
    "    query = queries[query_index]\n",
    "    n = 100\n",
    "    gold_matches = [x[\"id\"] for x in query[\"matches\"]]\n",
    "    \n",
    "    r = index.find(query[\"phrase\"], n=n)\n",
    "\n",
    "    rank = [str(i) for i in range(1, n + 1)]\n",
    "    \n",
    "    tooltips = \"\"\"\n",
    "        @tooltip\n",
    "    \"\"\"\n",
    "\n",
    "    p = bokeh.plotting.figure(\n",
    "        x_range=rank, plot_width=1000, plot_height=250,\n",
    "        title=f\"Scores for Query '{query['phrase']}'\",\n",
    "        toolbar_location=None, tools=\"\", tooltips=tooltips)\n",
    "    \n",
    "    doc_formatter = DocFormatter()\n",
    "\n",
    "    source = bokeh.models.ColumnDataSource({\n",
    "        'rank': rank,\n",
    "        'score': [m.score for m in r.matches],\n",
    "        'color': [(\"green\" if m.doc.unique_id in gold_matches else \"red\") for m in r.matches],\n",
    "        'tooltip': [doc_formatter(m.prepared_doc) for m in r.matches]\n",
    "    })\n",
    "    \n",
    "    hbar = p.vbar(\n",
    "        \"rank\", top=\"score\", color=\"color\", source=source)\n",
    "\n",
    "    p.y_range = bokeh.models.Range1d(0, 1)\n",
    "    p.xaxis.major_label_orientation = np.pi / 2\n",
    "\n",
    "    bokeh_handle = bokeh.io.show(p, notebook_handle=True)\n",
    "    \n",
    "    \n",
    "@interact(query_index=widgets.IntSlider(min=1, max=len(queries)))\n",
    "def illustrate(query_index):\n",
    "    illustrate_idea3(query_index - 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
