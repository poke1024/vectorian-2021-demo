{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "invalid-disaster",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'nbutils' from 'code/nbutils.py'>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ['VECTORIAN_CPP_IMPORT'] = \"1\"\n",
    "vectorian_path = Path(\"/Users/arbeit/Projects/vectorian-2021\")\n",
    "sys.path.append(str(vectorian_path))\n",
    "\n",
    "sys.path.append(\"code\")\n",
    "import nbutils\n",
    "\n",
    "import importlib\n",
    "importlib.reload(nbutils)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exterior-texas",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50b7cb2-2542-4573-ba41-ba27214c8e1f",
   "metadata": {},
   "source": [
    "Let's first get a high level overview of what we are aiming to do technically. We will experiment with four classes of embeddings (see the diagram below for a classification):\n",
    "\n",
    "* Static token embeddings: these operate on the token level such. We experiment with GloVe (Pennington et al. 2014), fastText (Mikolov et al., 2017) and Numberbatch (Speer et al, 2018). We use these three to compute token similarity and combine this with alignment algorithms (such as Waterman-Smith-Beyer) to compute document similarity. We also investigate the effect of stacking two static embeddings (fastText and Numberbatch).\n",
    "* Contextual token embeddings: these also operate on the token level, i.e. embeddings that change according to a specific token instance's context. In this notebook we experiment with using such token embeddings from a sentence bert model.\n",
    "* Document embeddings derived from specially trained models. Document embeddings represent one document via one single embedding. We use document embeddings obtained from a BERT model. More specifically, we use a Sentence-BERT model trained for the semantic textual similarity (STS) task (Reimers and Gurevych, 2019).\n",
    "* Document embeddings derived from token embeddings. We also experiment with averaging different kinds of token embeddings (static and contextual) to derive document embeddings.\n",
    "\n",
    "![Different kinds of embeddings](miscellaneous/diagram_embeddings.svg)\n",
    "\n",
    "For reasons of limited RAM and download times, we use small or compressed versions of the static embeddings we work with. For GloVe, we use the official 50-dimensional version of the 6B variant. For fastText we use a version that was compressed using the standard settings in https://github.com/avidale/compress-fasttext. For Numberbatch we use a 50-dimension version that was reduced using a standard PCA.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorrect-guidance",
   "metadata": {},
   "source": [
    "# Technical Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "measured-bikini",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1002\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1002\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error(url) {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.0.min.js\": \"HjagQp6T0/7bxYTAXbLotF1MLAGWmhkY5siA1Gc/pcEgvgRPtMsRn0gQtMwGKiw1\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.0.min.js\": \"ZEPPTjL+mdyqgIq+/pl9KTwzji8Kow2NnI3zWY8+sFinWP/SYJ80BnfeJsa45iYj\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.0.min.js\": \"exLqv2ACDRIaV7ZK1iL8aGzGYQvKVuT3U2CT7FsQREBxRah6JrkVCoFy0koY1YqV\"};\n",
       "\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      if (url in hashes) {\n",
       "        element.crossOrigin = \"anonymous\";\n",
       "        element.integrity = \"sha384-\" + hashes[url];\n",
       "      }\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.0.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1002\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.0.min.js\": \"HjagQp6T0/7bxYTAXbLotF1MLAGWmhkY5siA1Gc/pcEgvgRPtMsRn0gQtMwGKiw1\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.0.min.js\": \"ZEPPTjL+mdyqgIq+/pl9KTwzji8Kow2NnI3zWY8+sFinWP/SYJ80BnfeJsa45iYj\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.0.min.js\": \"exLqv2ACDRIaV7ZK1iL8aGzGYQvKVuT3U2CT7FsQREBxRah6JrkVCoFy0koY1YqV\"};\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      if (url in hashes) {\n        element.crossOrigin = \"anonymous\";\n        element.integrity = \"sha384-\" + hashes[url];\n      }\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.0.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import bokeh.io\n",
    "bokeh.io.output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beneficial-capital",
   "metadata": {},
   "source": [
    "# Choosing Static Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extreme-professional",
   "metadata": {},
   "source": [
    "First we need:\n",
    "    \n",
    "    * a set of documents of search over (i.e. our corpus)\n",
    "    * a set of word embeddings to employ for these searches\n",
    "    \n",
    "For the latter, we turn to Vectorian's embedding zoo, which offers a number of pretrained word embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "blond-rogers",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vectorian.embeddings import Zoo\n",
    "\n",
    "#Zoo.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "early-burden",
   "metadata": {},
   "source": [
    "Let's load the static embeddings as described above from Vectorian's model zoo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "alive-steel",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vectorian.embeddings import StackedEmbedding\n",
    "\n",
    "emb_glove = Zoo.load('glove-6B-50')\n",
    "emb_numberbatch = Zoo.load('numberbatch-19.08-en-50')\n",
    "emb_fasttext = Zoo.load('fasttext-en-mini')\n",
    "emb_fasttext_numberbatch = StackedEmbedding([emb_fasttext, emb_numberbatch])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e0a78e-030c-49ea-b49e-718fefebeeb6",
   "metadata": {},
   "source": [
    "We also instantiate an NLP parser based on sentence bert and a shim to use this model's token embeddings in the Vectorian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d7fe0d8-8f4d-4af8-9d19-4a7e3c7280c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy_sentence_bert\n",
    "nlp = spacy_sentence_bert.load_model('en_paraphrase_distilroberta_base_v1')\n",
    "\n",
    "from vectorian.embeddings import SentenceBertEmbedding\n",
    "emb_sbert = SentenceBertEmbedding(nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assigned-length",
   "metadata": {},
   "source": [
    "# Loading Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pursuant-apache",
   "metadata": {},
   "source": [
    "First load our gold standard that contains our queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "acoustic-passage",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"data/raw_data/gold.json\", \"r\") as f:\n",
    "    gold = nbutils.Gold(json.loads(f.read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "appreciated-circular",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['to be or not to be',\n",
       " 'sea of troubles',\n",
       " 'pampered jades of Asia',\n",
       " 'The rest is silence.',\n",
       " 'an old man is twice a child']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold.phrases[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "described-spending",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'ww_594e076e93ed4ccf',\n",
       "  'context': 'Perchance I have not told you all that I think; for not to be when you have been, I think is the greatest misery that may be.',\n",
       "  'quote': 'not to be when you have been, ',\n",
       "  'work': 'Those Five Questions (Tusculanae) (1561)',\n",
       "  'author': 'Marcus Tullius Cicero',\n",
       "  'lexia': 'to be or not to be',\n",
       "  'formal_class': 'Snowclone',\n",
       "  'complexity': 3}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold.matches('to be or not to be')[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extensive-pasta",
   "metadata": {},
   "source": [
    "We are now ready to build a Vectorian session that contains our documents and embeddings. We use preprocessed corpus data. For details, how this was achieved, see `code/prepare_corpus.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "graduate-painting",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Opening glove-6B-50: 100%|██████████\n",
      "Opening numberbatch-19.08-en-50: 100%|██████████\n",
      "1587it [00:00, 25329.19it/s]\n",
      "1587it [00:00, 11363.55it/s]\n"
     ]
    }
   ],
   "source": [
    "from vectorian.session import LabSession\n",
    "from vectorian.corpus import Corpus\n",
    "\n",
    "session = LabSession(\n",
    "    Corpus.load(\"data/processed_data/corpus\"),\n",
    "    embeddings=[\n",
    "        emb_sbert,\n",
    "        emb_glove,\n",
    "        emb_numberbatch,\n",
    "        emb_fasttext,\n",
    "        emb_fasttext_numberbatch],\n",
    "    normalizers=\"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91dc728a-816f-48bb-a12c-ac463c90dcef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35359794"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vectorian.metrics import TokenSimilarity, CosineSimilarity\n",
    "\n",
    "token_sim = TokenSimilarity(\n",
    "    emb_sbert,\n",
    "    CosineSimilarity())\n",
    "\n",
    "a = list(session.documents[0].spans(session.partition(\"document\")))[0][3]\n",
    "b = list(session.documents[3].spans(session.partition(\"document\")))[0][2]\n",
    "session.similarity(token_sim, a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informed-canal",
   "metadata": {},
   "source": [
    "Let's take a look at the documents we imported and that now live inside `session`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "stylish-secondary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddeb4e8db18447949f3b5eabe943a82b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='doc_browser', min=1), Output()), _dom_classes=('widget-i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "@interact(\n",
    "    doc_browser=widgets.IntSlider(min=1, max=len(session.documents)))\n",
    "def browse_docs(doc_browser):\n",
    "    doc = session.documents[doc_browser - 1]\n",
    "    display(widgets.HTML(nbutils.DocFormatter(gold)(doc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olympic-thursday",
   "metadata": {},
   "source": [
    "# Comparing Sentence Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seven-aggregate",
   "metadata": {},
   "source": [
    "In a first step, let's look at representing each document with one embedding in order to gather an understanding how different embedding strategies relate to the nearness of documents. We will later turn to individual token embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "average-controversy",
   "metadata": {},
   "source": [
    "We first prepare additional sentence embeddings using SBERT that we will show in our first big visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "planned-western",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert_encoder = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc9599d-402f-43dd-b234-b7e92ab16e4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "gentle-reservoir",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vectorian.embeddings import CachedPartitionEncoder, SpanEncoder\n",
    "\n",
    "sbert_encoder = CachedPartitionEncoder(SpanEncoder(\n",
    "    lambda texts: [nlp(t).vector for t in texts]))\n",
    "\n",
    "sbert_encoder.try_load(\"data/processed_data/doc_embeddings\")\n",
    "sbert_encoder.cache(session.documents, session.partition(\"document\"))\n",
    "sbert_encoder.save(\"data/processed_data/doc_embeddings\")\n",
    "\n",
    "sbert_encoder_name = nlp.meta[\"name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gorgeous-competition",
   "metadata": {},
   "source": [
    "We now show SBERT and a number of sentence embeddings we derive from word embeddings by simply averaging over the vectors (according to Mikolov et al., 2013).\n",
    "\n",
    "In the TSNE visualization below, dots are documents and the colors are the query that yields that document in our gold standard. By hovering over dots with the mouse you get details on the document and query the dot represents. Nearby dots of the same color indicate that the embedding tends to cluster documents similar to our gold standard.\n",
    "\n",
    "You can also add an intruder text by entering a text into the text field and pressing RETURN (to refresh the plot). This will move the larger crossed circle to where the currently selected embeddings thinks that the given text should be positioned in terms of the other documents.\n",
    "\n",
    "In some cases, we can clearly make out clusters visually. For example, in the fastText embedding the blue \"to be or not be\" documents are clustered nicely. SBERT shows a green cluster of \"an old man is twice a child\". numberbatch reveals a brown cluster of \"llo, ho, ho, my lord\".\n",
    "\n",
    "With spaCy transformers, we see some complex but noisy clustering. One example query: \"born naturally\".\n",
    "\n",
    "Finally you can switch between different embeddings using the radio buttons. You can also enable \"free_text\" and enter custom queries that are not in our gold corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ambient-forum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.bokehjs_exec.v0+json": "",
      "text/html": [
       "\n",
       "<script id=\"2365\">\n",
       "  var xhr = new XMLHttpRequest()\n",
       "  xhr.responseType = 'blob';\n",
       "  xhr.open('GET', \"http://localhost:64282/autoload.js?bokeh-autoload-element=2365&bokeh-absolute-url=http://localhost:64282&resources=none\", true);\n",
       "  \n",
       "  xhr.onload = function (event) {\n",
       "    var script = document.createElement('script'),\n",
       "    src = URL.createObjectURL(event.target.response);\n",
       "    script.src = src;\n",
       "    document.body.appendChild(script);\n",
       "  };\n",
       "xhr.send();\n",
       "</script>"
      ]
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "server_id": "739721bf15e943e9b0503755aaebfd38"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(nbutils)\n",
    "\n",
    "\n",
    "from ipywidgets import interact\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "\n",
    "plotter = nbutils.EmbeddingPlotter(session, nlp, gold, aggregator=np.mean)\n",
    "plotter.encoders[sbert_encoder_name] = sbert_encoder\n",
    "    \n",
    "bokeh.io.show(plotter.mk_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regional-supply",
   "metadata": {},
   "source": [
    "# Exploring Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becoming-disability",
   "metadata": {},
   "source": [
    "We now turn to single word embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "comparative-calendar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "memmap([-7.6663e-01,  6.9023e-01,  7.5462e-02,  1.1688e-01, -7.9722e-01,\n",
       "        -1.9606e-01, -7.7409e-01,  1.7351e-01,  2.6248e-01,  5.5295e-01,\n",
       "        -2.9190e-01, -2.4505e-01,  5.9885e-01,  1.2445e+00,  2.6401e-01,\n",
       "         2.0211e-01,  4.2139e-02,  5.1844e-01, -8.1704e-01, -1.0801e+00,\n",
       "         2.2864e-01,  9.1212e-02,  1.5638e+00,  7.5056e-01, -6.1206e-02,\n",
       "        -6.9001e-01, -5.3558e-01,  1.1311e+00,  1.3871e+00,  3.6151e-01,\n",
       "         2.8475e+00,  1.0733e-01, -1.7073e-02,  4.5358e-01, -7.1374e-03,\n",
       "         1.1177e-01, -1.5955e-01,  3.0205e-01,  5.4222e-01, -5.4103e-01,\n",
       "         2.3276e-01,  2.1756e-01, -4.1444e-02,  1.7056e-03,  7.6265e-01,\n",
       "         6.6241e-01, -4.5484e-02, -8.1479e-01,  4.6763e-02,  3.1134e-01],\n",
       "       dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.word_vec(emb_glove, \"hot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "quiet-venue",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70502234"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vectorian.metrics import TokenSimilarity, CosineSimilarity\n",
    "\n",
    "token_sim = TokenSimilarity(\n",
    "    emb_numberbatch,\n",
    "    CosineSimilarity()\n",
    ")\n",
    "\n",
    "session.similarity(token_sim, \"hot\", \"cold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "domestic-shower",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8010528"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_sim = TokenSimilarity(\n",
    "    emb_glove,\n",
    "    CosineSimilarity())\n",
    "\n",
    "session.similarity(token_sim, \"hot\", \"cold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romantic-daughter",
   "metadata": {},
   "source": [
    "The following interactive board allows you to search for a custom token inside a document. You can choose different documents by changing `doc_index`. The plot gives you the similarity of the entered token with the tokens in the chosen document under the selected embedding.\n",
    "\n",
    "Note that out-of-vocabulary words like \"fasterer\" will produce zero similarities under standard key-value embeddings, whereas fastText is still able to produce a vector thanks to subword information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "colored-participation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.bokehjs_exec.v0+json": "",
      "text/html": [
       "\n",
       "<script id=\"27621\">\n",
       "  var xhr = new XMLHttpRequest()\n",
       "  xhr.responseType = 'blob';\n",
       "  xhr.open('GET', \"http://localhost:49961/autoload.js?bokeh-autoload-element=27621&bokeh-absolute-url=http://localhost:49961&resources=none\", true);\n",
       "  \n",
       "  xhr.onload = function (event) {\n",
       "    var script = document.createElement('script'),\n",
       "    src = URL.createObjectURL(event.target.response);\n",
       "    script.src = src;\n",
       "    document.body.appendChild(script);\n",
       "  };\n",
       "xhr.send();\n",
       "</script>"
      ]
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "server_id": "17ed4c6d53dd4f97b8c33141b01ae786"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(nbutils)\n",
    "with open(\"data/raw_data/gold.json\", \"r\") as f:\n",
    "    gold = nbutils.Gold(json.loads(f.read()))\n",
    "    \n",
    "nbutils.plot_token_similarity(session, nlp, gold, n_figures=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retired-reverse",
   "metadata": {},
   "source": [
    "# A Search Query using Alignment over Similar Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0aea237-1fe6-4903-89c9-328d7f9790c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(nbutils)\n",
    "\n",
    "\n",
    "def make_index_builder():\n",
    "    return nbutils.InteractiveIndexBuilder(session, nlp, partition_encoders={\n",
    "        sbert_encoder_name: sbert_encoder\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "certain-bullet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbb9b59934c747db93f29b025c9eaf16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(HTML(value='<p>Partition similarity is computed via alignment using <b>Waterman-Smith-Beyer</b> …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_builder = make_index_builder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cloudy-dividend",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'to be or not to be'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold.phrases[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eleven-nerve",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\t<iframe\n",
       "\t\tid=\"vectorian-1620223200131833000-140487141614784-1\"\n",
       "\t\twidth=\"100%\"\n",
       "\t\theight=\"100%\"\n",
       "\t\tsrcdoc=\"&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset=&quot;utf-8&quot;&gt;&lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1&quot;&gt;&lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bulma@0.9.1/css/bulma.min.css&quot; /&gt;&lt;/head&gt;&lt;body&gt;&lt;div class=&quot;container&quot; height=&quot;100%&quot;&gt;&lt;div class=&quot;section&quot;&gt;&lt;article class=&quot;media&quot;&gt;&lt;div class=&quot;media-left&quot;&gt;&lt;p class=&quot;image is-64x64&quot;&gt;&lt;span class=&quot;buttons&quot;&gt;&lt;span class=&quot;has-text-weight-bold&quot;&gt;96.6%&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;media-content&quot;&gt;&lt;div class=&quot;is-pulled-right&quot;&gt;&lt;small&gt;Thomas Middleton&lt;/small&gt;&lt;small class=&quot;is-italic&quot;&gt;, The Phoenix (1604)&lt;/small&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;br /&gt;&lt;span&gt;&lt;span class=&quot;has-text-grey-light&quot;&gt;attempt, molest, or incumber any part, or parts whatsoever, either &lt;/span&gt; &lt;span&gt;&lt;span style=&quot;display:inline-table;&quot;&gt;&lt;span style=&quot;display:table-row;&quot;&gt;&lt;span style=&quot;display:table-cell;&quot;&gt;&lt;span class=&quot;has-text-black has-text-weight-bold&quot;&gt;to&lt;/span&gt; &lt;/span&gt;&lt;span style=&quot;display:table-cell;&quot;&gt;&lt;span class=&quot;tag is-light&quot;&gt;to&lt;/span&gt; &lt;/span&gt;&lt;span style=&quot;display:table-cell; opacity:1.0;&quot;&gt;&lt;span class=&quot;tag is-success&quot;&gt;100%&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style=&quot;display:inline-table;&quot;&gt;&lt;span style=&quot;display:table-row;&quot;&gt;&lt;span style=&quot;display:table-cell;&quot;&gt;&lt;span class=&quot;has-text-black has-text-weight-bold&quot;&gt;be&lt;/span&gt; &lt;/span&gt;&lt;span style=&quot;display:table-cell;&quot;&gt;&lt;span class=&quot;tag is-light&quot;&gt;be&lt;/span&gt; &lt;/span&gt;&lt;span style=&quot;display:table-cell; opacity:1.0;&quot;&gt;&lt;span class=&quot;tag is-success&quot;&gt;100%&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;has-text-grey-light&quot;&gt;named &lt;/span&gt; &lt;span&gt;&lt;span style=&quot;display:inline-table;&quot;&gt;&lt;span style=&quot;display:table-row;&quot;&gt;&lt;span style=&quot;display:table-cell;&quot;&gt;&lt;span class=&quot;has-text-black has-text-weight-bold&quot;&gt;or&lt;/span&gt; &lt;/span&gt;&lt;span style=&quot;display:table-cell;&quot;&gt;&lt;span class=&quot;tag is-light&quot;&gt;or&lt;/span&gt; &lt;/span&gt;&lt;span style=&quot;display:table-cell; opacity:1.0;&quot;&gt;&lt;span class=&quot;tag is-success&quot;&gt;100%&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style=&quot;display:inline-table;&quot;&gt;&lt;span style=&quot;display:table-row;&quot;&gt;&lt;span style=&quot;display:table-cell;&quot;&gt;&lt;span class=&quot;has-text-black has-text-weight-bold&quot;&gt;not&lt;/span&gt; &lt;/span&gt;&lt;span style=&quot;display:table-cell;&quot;&gt;&lt;span class=&quot;tag is-light&quot;&gt;not&lt;/span&gt; &lt;/span&gt;&lt;span style=&quot;display:table-cell; opacity:1.0;&quot;&gt;&lt;span class=&quot;tag is-success&quot;&gt;100%&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style=&quot;display:inline-table;&quot;&gt;&lt;span style=&quot;display:table-row;&quot;&gt;&lt;span style=&quot;display:table-cell;&quot;&gt;&lt;span class=&quot;has-text-black has-text-weight-bold&quot;&gt;to&lt;/span&gt; &lt;/span&gt;&lt;span style=&quot;display:table-cell;&quot;&gt;&lt;span class=&quot;tag is-light&quot;&gt;to&lt;/span&gt; &lt;/span&gt;&lt;span style=&quot;display:table-cell; opacity:1.0;&quot;&gt;&lt;span class=&quot;tag is-success&quot;&gt;100%&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style=&quot;display:inline-table;&quot;&gt;&lt;span style=&quot;display:table-row;&quot;&gt;&lt;span style=&quot;display:table-cell;&quot;&gt;&lt;span class=&quot;has-text-black has-text-weight-bold&quot;&gt;be&lt;/span&gt; &lt;/span&gt;&lt;span style=&quot;display:table-cell;&quot;&gt;&lt;span class=&quot;tag is-light&quot;&gt;be&lt;/span&gt; &lt;/span&gt;&lt;span style=&quot;display:table-cell; opacity:1.0;&quot;&gt;&lt;span class=&quot;tag is-success&quot;&gt;100%&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;has-text-grey-light&quot;&gt;named, either hidden or unhidden, either those that boldly look &lt;/span&gt;&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/article&gt;&lt;/div&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;&lt;script&gt;\n",
       "\t\t(function() {\n",
       "\t\t\tvar f = parent.document.getElementById(&#x27;vectorian-1620223200131833000-140487141614784-1&#x27;);\n",
       "\t\t\tf.height = f.contentWindow.document.body.scrollHeight + &#x27;px&#x27;;\n",
       "\t\t})();\n",
       "\t&lt;/script&gt;\"\n",
       "\t\tonload=\"\n",
       "\t\t(function() {\n",
       "\t\t\tvar f = parent.document.getElementById('vectorian-1620223200131833000-140487141614784-1');\n",
       "\t\t\tf.height = f.contentWindow.document.body.scrollHeight + 'px';\n",
       "\t\t})();\n",
       "\t\"\n",
       "\t\tframeborder=\"0\"\n",
       "\t\tallowfullscreen\n",
       "\t></iframe>\n",
       "\t"
      ],
      "text/plain": [
       "<vectorian.session.LabResult at 0x7fc5b612b700>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_builder.build_index().find(gold.phrases[0], n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "labeled-helen",
   "metadata": {},
   "source": [
    "# Plotting the NDCG over the Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "61f9f310-7e48-467f-83d3-0bfd1120faa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import importlib\n",
    "importlib.reload(nbutils)\n",
    "\n",
    "import json\n",
    "\n",
    "with open(\"data/raw_data/gold.json\", \"r\") as f:\n",
    "    gold = nbutils.Gold(json.loads(f.read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b413a21e-c6cf-4f9d-8da1-3717281da294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "125f49ed9eef4051a9b004b637b39de0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(HTML(value='<p>Partition similarity is computed via alignment using <b>Waterman-Smith-Beyer</b> …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(nbutils)\n",
    "\n",
    "index_builder = make_index_builder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "premium-warehouse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"3ceabd87-a186-4f12-a78a-0ec5bf3062fe\" data-root-id=\"1906\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"3f74525a-8ae1-4fdb-8e45-a47a80cf8dac\":{\"defs\":[{\"extends\":null,\"module\":null,\"name\":\"DataModel\",\"overrides\":[],\"properties\":[]}],\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"1917\"}],\"center\":[{\"id\":\"1920\"},{\"id\":\"1923\"},{\"id\":\"1933\"}],\"height\":400,\"left\":[{\"id\":\"1921\"}],\"renderers\":[{\"id\":\"1931\"}],\"title\":{\"id\":\"1907\"},\"toolbar\":{\"id\":\"1924\"},\"toolbar_location\":null,\"width\":1000,\"x_range\":{\"id\":\"1925\"},\"x_scale\":{\"id\":\"1913\"},\"y_range\":{\"id\":\"1911\"},\"y_scale\":{\"id\":\"1915\"}},\"id\":\"1906\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{},\"id\":\"1997\",\"type\":\"Selection\"},{\"attributes\":{\"axis\":{\"id\":\"1921\"},\"dimension\":1,\"ticker\":null,\"visible\":false},\"id\":\"1923\",\"type\":\"Grid\"},{\"attributes\":{\"active_multi\":null},\"id\":\"1924\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"1992\",\"type\":\"AllLabels\"},{\"attributes\":{\"high\":1,\"low\":0,\"palette\":[\"#66c2a5\",\"#fc8d62\",\"#8da0cb\"]},\"id\":\"1927\",\"type\":\"LinearColorMapper\"},{\"attributes\":{},\"id\":\"1922\",\"type\":\"CategoricalTicker\"},{\"attributes\":{},\"id\":\"1995\",\"type\":\"AllLabels\"},{\"attributes\":{\"formatter\":{\"id\":\"1994\"},\"major_label_policy\":{\"id\":\"1995\"},\"ticker\":{\"id\":\"1922\"}},\"id\":\"1921\",\"type\":\"CategoricalAxis\"},{\"attributes\":{},\"id\":\"1996\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"axis\":{\"id\":\"1917\"},\"ticker\":null},\"id\":\"1920\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1915\",\"type\":\"CategoricalScale\"},{\"attributes\":{},\"id\":\"1918\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1907\",\"type\":\"Title\"},{\"attributes\":{\"factors\":[\"O all you host of heaven!\",\"hell itself should gape\",\"frailty, thy name is woman\",\"we will not carry coals\",\"All the world's a stage\",\"livers white as milk\",\"I do bear a brain.\",\"planets strike\",\"though this be madness, yet there is method in it\",\"Illo, ho, ho, my lord\",\"springes to catch woodcocks\",\"thereby hangs a tale\",\"go, by Saint Hieronimo\",\"a horse, a horse, my kingdom for a horse\",\"In my mind's eye\",\"an old man is twice a child\",\"The rest is silence.\",\"pampered jades of Asia\",\"sea of troubles\",\"to be or not to be\",\"mean NDCG\"]},\"id\":\"1911\",\"type\":\"FactorRange\"},{\"attributes\":{},\"id\":\"1913\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1925\",\"type\":\"Range1d\"},{\"attributes\":{\"axis_label\":\"NDCG\",\"formatter\":{\"id\":\"1991\"},\"major_label_policy\":{\"id\":\"1992\"},\"ticker\":{\"id\":\"1918\"}},\"id\":\"1917\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1991\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"data\":{\"color\":[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0],\"ndcg\":[1.0,0.871018594835653,0.9828920819566879,0.8876811557409314,0.8065735963827293,0.6423207097347345,0.9828920819566879,1.0,0.36665417549105206,0.9486219356678827,1.0,1.0,1.0,1.0,0.7342858411313754,0.9460116107704118,1.0,1.0,1.0,0.9833860877947811,0.9076168935731465],\"ndcg_str\":[\"100.0%\",\"87.1%\",\"98.3%\",\"88.8%\",\"80.7%\",\"64.2%\",\"98.3%\",\"100.0%\",\"36.7%\",\"94.9%\",\"100.0%\",\"100.0%\",\"100.0%\",\"100.0%\",\"73.4%\",\"94.6%\",\"100.0%\",\"100.0%\",\"100.0%\",\"98.3%\",\"90.8%\"],\"phrase\":[\"O all you host of heaven!\",\"hell itself should gape\",\"frailty, thy name is woman\",\"we will not carry coals\",\"All the world's a stage\",\"livers white as milk\",\"I do bear a brain.\",\"planets strike\",\"though this be madness, yet there is method in it\",\"Illo, ho, ho, my lord\",\"springes to catch woodcocks\",\"thereby hangs a tale\",\"go, by Saint Hieronimo\",\"a horse, a horse, my kingdom for a horse\",\"In my mind's eye\",\"an old man is twice a child\",\"The rest is silence.\",\"pampered jades of Asia\",\"sea of troubles\",\"to be or not to be\",\"mean NDCG\"]},\"selected\":{\"id\":\"1997\"},\"selection_policy\":{\"id\":\"1996\"}},\"id\":\"1926\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"1994\",\"type\":\"CategoricalTickFormatter\"},{\"attributes\":{\"source\":{\"id\":\"1926\"}},\"id\":\"1932\",\"type\":\"CDSView\"},{\"attributes\":{\"fill_color\":{\"field\":\"color\",\"transform\":{\"id\":\"1927\"}},\"height\":{\"value\":0.75},\"line_color\":{\"field\":\"color\",\"transform\":{\"id\":\"1927\"}},\"right\":{\"field\":\"ndcg\"},\"y\":{\"field\":\"phrase\"}},\"id\":\"1929\",\"type\":\"HBar\"},{\"attributes\":{\"data_source\":{\"id\":\"1926\"},\"glyph\":{\"id\":\"1929\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1930\"},\"view\":{\"id\":\"1932\"}},\"id\":\"1931\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"field\":\"color\",\"transform\":{\"id\":\"1927\"}},\"height\":{\"value\":0.75},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"field\":\"color\",\"transform\":{\"id\":\"1927\"}},\"right\":{\"field\":\"ndcg\"},\"y\":{\"field\":\"phrase\"}},\"id\":\"1930\",\"type\":\"HBar\"},{\"attributes\":{\"level\":\"glyph\",\"source\":{\"id\":\"1926\"},\"text\":{\"field\":\"ndcg_str\"},\"text_align\":{\"value\":\"right\"},\"text_baseline\":{\"value\":\"middle\"},\"text_color\":{\"value\":\"white\"},\"text_font_size\":{\"value\":\"8pt\"},\"x\":{\"field\":\"ndcg\"},\"y\":{\"field\":\"phrase\"}},\"id\":\"1933\",\"type\":\"LabelSet\"}],\"root_ids\":[\"1906\"]},\"title\":\"Bokeh Application\",\"version\":\"2.3.0\"}};\n",
       "  var render_items = [{\"docid\":\"3f74525a-8ae1-4fdb-8e45-a47a80cf8dac\",\"notebook_comms_target\":\"1998\",\"root_ids\":[\"1906\"],\"roots\":{\"1906\":\"3ceabd87-a186-4f12-a78a-0ec5bf3062fe\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1906"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nbutils.plot_ndcgs(gold, index_builder.build_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tough-endorsement",
   "metadata": {},
   "source": [
    "# Focussing in on single queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7c2ea40e-0ff0-4385-80be-d35c1b8f4e43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8110f7a142f4d139ef8292aaf0e4b0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(HTML(value='<p>Partition similarity is computed via alignment using <b>Waterman-Smith-Beyer</b> …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(nbutils)\n",
    "\n",
    "index_builder = make_index_builder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "third-thanks",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.bokehjs_exec.v0+json": "",
      "text/html": [
       "\n",
       "<script id=\"2155\">\n",
       "  var xhr = new XMLHttpRequest()\n",
       "  xhr.responseType = 'blob';\n",
       "  xhr.open('GET', \"http://localhost:64230/autoload.js?bokeh-autoload-element=2155&bokeh-absolute-url=http://localhost:64230&resources=none\", true);\n",
       "  \n",
       "  xhr.onload = function (event) {\n",
       "    var script = document.createElement('script'),\n",
       "    src = URL.createObjectURL(event.target.response);\n",
       "    script.src = src;\n",
       "    document.body.appendChild(script);\n",
       "  };\n",
       "xhr.send();\n",
       "</script>"
      ]
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "server_id": "dec47677eb8b4557a411e6ea4215fec8"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6103c061d1c949fcb0a431f9dc92b537",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nbutils.plot_results(gold, index_builder.build_index(), query=\"though this be madness\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23c05c8-31e3-4736-8312-687f48bfc884",
   "metadata": {},
   "source": [
    "# Literaturliste\n",
    "\n",
    "Pennington, Jeffrey, et al. “Glove: Global Vectors for Word Representation.” Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), Association for Computational Linguistics, 2014, pp. 1532–43. DOI.org (Crossref), doi:10.3115/v1/D14-1162.\n",
    "\n",
    "Mikolov, Tomas, et al. “Advances in Pre-Training Distributed Word Representations.” ArXiv:1712.09405 [Cs], Dec. 2017. arXiv.org, http://arxiv.org/abs/1712.09405.\n",
    "\n",
    "Speer, Robyn, et al. “ConceptNet 5.5: An Open Multilingual Graph of General Knowledge.” ArXiv:1612.03975 [Cs], Dec. 2018. arXiv.org, http://arxiv.org/abs/1612.03975.\n",
    "\n",
    "Reimers, Nils, and Iryna Gurevych. “Sentence-BERT: Sentence Embeddings Using Siamese BERT-Networks.” ArXiv:1908.10084 [Cs], Aug. 2019. arXiv.org, http://arxiv.org/abs/1908.10084."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
