{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336e2ae0-3099-4e08-9aa2-70a567b9163d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"code\")\n",
    "import nbutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b6be29-90ac-4c33-a466-a1739dd4d241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# important: tell the notebook logic whether we have a full bokeh server\n",
    "# this IS the case for local jupyter installations, but is NOT the case\n",
    "# for notebooks running on mybinder.\n",
    "nbutils.initialize(has_bokeh_server=False)  # change to True if local jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exterior-texas",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50b7cb2-2542-4573-ba41-ba27214c8e1f",
   "metadata": {},
   "source": [
    "Let's first get a high level overview of what we are aiming to do technically. We will experiment with four classes of embeddings (see the diagram below for a classification):\n",
    "\n",
    "* Static token embeddings: these operate on the token level such. We experiment with GloVe (Pennington et al. 2014), fastText (Mikolov et al., 2017) and Numberbatch (Speer et al, 2018). We use these three to compute token similarity and combine this with alignment algorithms (such as Waterman-Smith-Beyer) to compute document similarity. We also investigate the effect of stacking two static embeddings (fastText and Numberbatch).\n",
    "* Contextual token embeddings: these also operate on the token level, i.e. embeddings that change according to a specific token instance's context. In this notebook we experiment with using such token embeddings from a sentence bert model.\n",
    "* Document embeddings derived from specially trained models. Document embeddings represent one document via one single embedding. We use document embeddings obtained from a BERT model. More specifically, we use a Sentence-BERT model trained for the semantic textual similarity (STS) task (Reimers and Gurevych, 2019).\n",
    "* Document embeddings derived from token embeddings. We also experiment with averaging different kinds of token embeddings (static and contextual) to derive document embeddings.\n",
    "\n",
    "![Different kinds of embeddings](miscellaneous/diagram_embeddings.svg)\n",
    "\n",
    "For reasons of limited RAM and download times, we use small or compressed versions of the static embeddings we work with. For GloVe, we use the official 50-dimensional version of the 6B variant. For fastText we use a version that was compressed using the standard settings in https://github.com/avidale/compress-fasttext. For Numberbatch we use a 50-dimension version that was reduced using a standard PCA.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorrect-guidance",
   "metadata": {},
   "source": [
    "# Technical Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "measured-bikini",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bokeh.io\n",
    "bokeh.io.output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beneficial-capital",
   "metadata": {},
   "source": [
    "# Choosing Static Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extreme-professional",
   "metadata": {},
   "source": [
    "First we need:\n",
    "    \n",
    "    * a set of documents of search over (i.e. our corpus)\n",
    "    * a set of word embeddings to employ for these searches\n",
    "    \n",
    "For the latter, we turn to Vectorian's embedding zoo, which offers a number of pretrained word embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blond-rogers",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vectorian.embeddings import Zoo\n",
    "\n",
    "#Zoo.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "early-burden",
   "metadata": {},
   "source": [
    "Let's load the static embeddings as described above from Vectorian's model zoo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alive-steel",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vectorian.embeddings import StackedEmbedding\n",
    "\n",
    "emb_glove = Zoo.load('glove-6B-50')\n",
    "emb_numberbatch = Zoo.load('numberbatch-19.08-en-50')\n",
    "emb_fasttext = Zoo.load('fasttext-en-mini')\n",
    "emb_fasttext_numberbatch = StackedEmbedding([emb_fasttext, emb_numberbatch])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e0a78e-030c-49ea-b49e-718fefebeeb6",
   "metadata": {},
   "source": [
    "We also instantiate an NLP parser based on sentence bert and a shim to use this model's token embeddings in the Vectorian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7fe0d8-8f4d-4af8-9d19-4a7e3c7280c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy_sentence_bert\n",
    "nlp = spacy_sentence_bert.load_model('en_paraphrase_distilroberta_base_v1')\n",
    "\n",
    "from vectorian.embeddings import SentenceBertEmbedding\n",
    "emb_sbert = SentenceBertEmbedding(nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assigned-length",
   "metadata": {},
   "source": [
    "# Loading Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pursuant-apache",
   "metadata": {},
   "source": [
    "First load our gold standard that contains our queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acoustic-passage",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"data/raw_data/gold.json\", \"r\") as f:\n",
    "    gold = nbutils.Gold(json.loads(f.read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appreciated-circular",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold.phrases[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "described-spending",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold.matches('to be or not to be')[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extensive-pasta",
   "metadata": {},
   "source": [
    "We are now ready to build a Vectorian session that contains our documents and embeddings. We use preprocessed corpus data. For details, how this was achieved, see `code/prepare_corpus.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graduate-painting",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vectorian.session import LabSession\n",
    "from vectorian.corpus import Corpus\n",
    "\n",
    "session = LabSession(\n",
    "    Corpus.load(\"data/processed_data/corpus\"),\n",
    "    embeddings=[\n",
    "        emb_sbert,\n",
    "        emb_glove,\n",
    "        emb_numberbatch,\n",
    "        emb_fasttext,\n",
    "        emb_fasttext_numberbatch],\n",
    "    normalizers=\"default\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informed-canal",
   "metadata": {},
   "source": [
    "Let's take a look at the gold standard we imported and whose documents now live inside `session`. We have 20 queries (blue circles), and for each query we have a number of documents (green circles) that we regard as correct matches to these queries. All documents that are not attached to the query are - by definition - no correct matches.\n",
    "\n",
    "Note for interactive users: you can hover your mouse over the nodes to see their content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c0a4e2-5640-43eb-8950-394da395f5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbutils.plot_gold(gold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b2bcfd-c597-44c3-81bc-34cbab10bdef",
   "metadata": {},
   "source": [
    "# What are Word Embeddings?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d7b8be-f3b6-4604-b924-7a453ddc89d0",
   "metadata": {},
   "source": [
    "We now turn to single word embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2633d27-0863-4958-bf06-036b8af37604",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.word_vec(emb_glove, \"hot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b95ce2-cdc8-44dc-a69e-06c3c1feb318",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vectorian.metrics import TokenSimilarity, CosineSimilarity\n",
    "\n",
    "token_sim = TokenSimilarity(\n",
    "    emb_numberbatch,\n",
    "    CosineSimilarity()\n",
    ")\n",
    "\n",
    "session.similarity(token_sim, \"hot\", \"cold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82787688-a005-4bab-bcff-5954b333ac3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_sim = TokenSimilarity(\n",
    "    emb_glove,\n",
    "    CosineSimilarity())\n",
    "\n",
    "session.similarity(token_sim, \"hot\", \"cold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96153b53-e9c4-4201-a55d-3d90e7d4f3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_sim = TokenSimilarity(\n",
    "    emb_sbert,\n",
    "    CosineSimilarity())\n",
    "\n",
    "a = list(session.documents[0].spans(session.partition(\"document\")))[0][3]\n",
    "b = list(session.documents[3].spans(session.partition(\"document\")))[0][2]\n",
    "session.similarity(token_sim, a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98c4165-4cd5-4083-92f7-ba28c34e2af3",
   "metadata": {},
   "source": [
    "# Exploring Word Embedding (and our data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1942597d-d5db-48e1-b02f-bb1f8084cb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbutils.browse(gold, \"rest is silence\", \"Fig for Fortune\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427bc950-6e6d-4585-b98f-688484df28e9",
   "metadata": {},
   "source": [
    "This is an example, where similarity and therefore embeddings won't help us much. The syntactic structure is mirrored, and \"silence\" is replaced with \"all but wind\". Even if we focus on nouns only, \"silence\" and \"wind\" are not generally similar. Still an embedding approach should be able to recognize that the  words at the beginning of phrase are exact matches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa324fc-042b-474c-9ac2-6c28e61d4a41",
   "metadata": {},
   "source": [
    "If we inspect the cosine similarity of the token \"silence\" with other tokens in the context under three of our embeddings, we see that there is more connection between \"silence\" and \"wind\" than we expected. Still, the absolute value of 0.3 for numberbatch is low. Interestingly, glove associates \"silence\" with \"action\", i.e. an opposite. The phenomenon that embeddings sometimes cluster opposites is a common observation and can be an issue when wanting to differentiate between these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd65bcc2-678a-4cdb-8a04-99df700c33b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(nbutils)\n",
    "\n",
    "nbutils.plot_token_similarity(session, nlp, gold, \"silence\", \"Fig for Fortune\", n_figures=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd41a31d-d7c0-4bb7-8fc7-adb824a7fbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbutils.browse(gold, \"sea of troubles\", \"Book of Common Prayer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadfacd0-75f9-4cb5-a7a6-927b4e82ca42",
   "metadata": {},
   "source": [
    "This is a different example, where similarity computation might help. Here, \"sea\" is replaced by \"waves\", and \"troubles\" by \"troublesome\". We should expect to get reasonable results with results on this instance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c58bda-6bbc-49b9-8f91-01ec5ea660d4",
   "metadata": {},
   "source": [
    "Indeed, by inspecting the cosine similarity of the token \"sea\" with other tokens in the context, we see that this is true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae847b0b-2ea7-4e97-994f-405d32e3bc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbutils.plot_token_similarity(session, nlp, gold, \"sea\", \"The Book of Common Prayer\", n_figures=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc2c55b-2194-436a-94f8-dde47505d07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbutils.plot_token_similarity(session, nlp, gold, \"troubles\", \"The Book of Common Prayer\", n_figures=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b97c62-4bef-48f6-8c08-83b585afd4ca",
   "metadata": {},
   "source": [
    "Note how out-of-vocabulary words like \"troublesomest\" will produce zero similarities under standard key-value embeddings, whereas fastText is still able to produce a vector thanks to subword information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ddff82-b84e-4289-a409-debc26d87287",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbutils.plot_token_similarity(session, nlp, gold, \"troublesomest\", \"The Book of Common Prayer\", n_figures=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seven-aggregate",
   "metadata": {},
   "source": [
    "Before we turn to alignment strategies to match sentences token by token, we first look at representing each document with one embedding in order to gather an understanding how different embedding strategies relate to the nearness of documents. We will later turn to individual token embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "average-controversy",
   "metadata": {},
   "source": [
    "We first prepare additional sentence embeddings using SBERT that we will show in our first big visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gentle-reservoir",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vectorian.embeddings import CachedPartitionEncoder, SpanEncoder\n",
    "\n",
    "sbert_encoder = CachedPartitionEncoder(SpanEncoder(\n",
    "    lambda texts: [nlp(t).vector for t in texts]))\n",
    "\n",
    "sbert_encoder.try_load(\"data/processed_data/doc_embeddings\")\n",
    "sbert_encoder.cache(session.documents, session.partition(\"document\"))\n",
    "sbert_encoder.save(\"data/processed_data/doc_embeddings\")\n",
    "\n",
    "sbert_encoder_name = nlp.meta[\"name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d93851-2895-422d-92d0-586aa540d480",
   "metadata": {},
   "source": [
    "Now we construct an Explorer class. In addition to providing the SBERT encoder we just built, we configure the Explorer to use averaging to build documents embeddings from token embeddings.\n",
    "\n",
    "Note to interactive readers: you can change the \"mean\" (averaging) method to other methods for computing document tokens as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6fb8cc-5328-483c-becd-9a86fb091192",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(nbutils)\n",
    "\n",
    "\n",
    "doc_embedding_explorer = nbutils.DocEmbeddingExplorer(\n",
    "    session=session, nlp=nlp, gold=gold, extra_encoders={sbert_encoder_name: sbert_encoder})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724ecd2c-91c3-4dd5-af4a-ac578d2a0183",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_embedding_explorer.plot([\n",
    "    {\"encoder\": \"paraphrase_distilroberta\", \"locator\": (\"fixed\", \"carry coals\"), 'has_tok_emb': False},\n",
    "    {\"encoder\": \"paraphrase_distilroberta\", \"locator\": (\"fixed\", \"an old man is twice\"), 'has_tok_emb': False}\n",
    "]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755fbac7-6a37-411a-9611-42022952a250",
   "metadata": {},
   "source": [
    "In the TSNE visualization above, dots are documents and the colors are the query that yields that document in our gold standard. By hovering over dots with the mouse you get details on the document and query the dot represents. Nearby dots of the same color indicate that the embedding tends to cluster documents similar to our gold standard."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5bcebe-bb6c-467c-a147-d7588e28917b",
   "metadata": {},
   "source": [
    "On the left above, we see that the phrase \"we will not carry coals\" (large green-yellow circle with cross) in located closely to the documents associated with that query (smaller green-yellow circles). Similarly, on the right we see that the phrase \"an old man is twice a child\" clusters with the actual (green) documents we associate with it in our gold standard.\n",
    "\n",
    "For these phrases and documents, the `paraphrase_distilroberta` model does a good job of producing a document embedding that actually separates inherent topics (without us telling it to do it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ambient-forum",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_embedding_explorer.plot([\n",
    "    {\"encoder\": \"numberbatch\", \"selection\": [\n",
    "        'ww_32c26a7909c83bda',\n",
    "        'ww_b5b8083a6a1282bc',\n",
    "        'ww_9a6cb20b0b157545',\n",
    "        'ww_a6f4b0e3428ad510',\n",
    "        'ww_8e68a517bc3ecceb']}\n",
    "]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe93e356-ec78-442b-b445-d9f5b6c2ed25",
   "metadata": {},
   "source": [
    "In the plot above we look at the document embedding produced by a **token-based** embedding. This has the advantage that we can actually look at token embeddings that make up the document embedding (through averaging). On the right side, we see a TSNE plot of all token embeddings that occur in the documents that are selected on the left. The hope is that this visualization will give us a clue why the documents on the left might be clustered."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0564ef2d-c165-44ed-a930-f85b9cd7f3d2",
   "metadata": {},
   "source": [
    "The red circles on the left represent contexts that match the phrase \"a horse, a horse, my kingform for a horse\" are mapped. If we look at the token embeddings (that includes documents from other other classes), we indeed see that a grouping happens due to word embeddings clustering around \"horse\" (right side), but we also see a cluster around \"boat\", \"sail\" and \"river\" on the left.\n",
    "\n",
    "In fact context 1 contains \"muscle boat\", context 2 contains \"To swim the river villain\", and context 3 contains \"A boat, a boat\". We thereby see that this kind of unsupervised document clustering clusters items due to inherent qualities that might not actually match our query criteria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a554d4e-9eb9-49f9-900e-ab554afd2757",
   "metadata": {},
   "source": [
    "Interactive note: you can compute different token embeddings plots by selecting different documents on the mouse (drag the mouse to lasso)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a490bb-2a3c-4ae2-a687-2b74d60d4eb7",
   "metadata": {},
   "source": [
    "# Understanding Alignments (WSB vs WMD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retired-reverse",
   "metadata": {},
   "source": [
    "## A Search Query using Alignment over Similar Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0aea237-1fe6-4903-89c9-328d7f9790c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(nbutils)\n",
    "\n",
    "\n",
    "def make_index_builder():\n",
    "    return nbutils.InteractiveIndexBuilder(session, nlp, partition_encoders={\n",
    "        sbert_encoder_name: sbert_encoder\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certain-bullet",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_builder = make_index_builder()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb2ff05-1807-4343-a819-9acb55328ccc",
   "metadata": {},
   "source": [
    "What you see above is the description of a search strategy that we will employ in the following sections of this notebook. Interactive readers can switch to the \"Edit\" part and actually explore the setting in more detail and even change it to something completely different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cloudy-dividend",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold.phrases[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eleven-nerve",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_builder.build_index().find(gold.phrases[0], n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "labeled-helen",
   "metadata": {},
   "source": [
    "## Plotting the NDCG over the Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b413a21e-c6cf-4f9d-8da1-3717281da294",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_builder = make_index_builder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premium-warehouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbutils.plot_ndcgs(gold, index_builder.build_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tough-endorsement",
   "metadata": {},
   "source": [
    "## Focussing on single queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2ea40e-0ff0-4385-80be-d35c1b8f4e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_builder = make_index_builder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "third-thanks",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbutils.plot_results(gold, index_builder.build_index(), query=\"though this be madness\", rank=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148bad50-844b-4712-ac81-ff286e2dc17a",
   "metadata": {},
   "source": [
    "# Interactive Searches with Your Own Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316d07be-ff26-4a56-966a-38450fd29c1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e23c05c8-31e3-4736-8312-687f48bfc884",
   "metadata": {},
   "source": [
    "# Literaturliste\n",
    "\n",
    "Pennington, Jeffrey, et al. “Glove: Global Vectors for Word Representation.” Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), Association for Computational Linguistics, 2014, pp. 1532–43. DOI.org (Crossref), doi:10.3115/v1/D14-1162.\n",
    "\n",
    "Mikolov, Tomas, et al. “Advances in Pre-Training Distributed Word Representations.” ArXiv:1712.09405 [Cs], Dec. 2017. arXiv.org, http://arxiv.org/abs/1712.09405.\n",
    "\n",
    "Speer, Robyn, et al. “ConceptNet 5.5: An Open Multilingual Graph of General Knowledge.” ArXiv:1612.03975 [Cs], Dec. 2018. arXiv.org, http://arxiv.org/abs/1612.03975.\n",
    "\n",
    "Reimers, Nils, and Iryna Gurevych. “Sentence-BERT: Sentence Embeddings Using Siamese BERT-Networks.” ArXiv:1908.10084 [Cs], Aug. 2019. arXiv.org, http://arxiv.org/abs/1908.10084."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6bb881-499f-497b-a5df-f27d1f5205e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66665261-8c38-47f4-9371-91e43bfbd094",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
